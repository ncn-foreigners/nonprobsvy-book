[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modern inference methods for non-probability samples with R",
    "section": "",
    "text": "1 Nomenclature\n\n\n\n\n\n\n\nsymbol\nMeaning\n\n\n\n\n\\(\\mathbb{E}\\)\nExpected value operator\n\n\nN\nTrue population size\n\n\n\\(\\mathcal{U}\\)\nFinite population with N units\n\n\ny\nResponse variable\n\n\n\\(\\bx\\)\nAuxiliary variables\n\n\np\nNumber of auxiliary variables\n\n\n\\(S_A\\)\nNonprobablity sample\n\n\n\\(S_B\\)\nProbability sample\n\n\n\\(\\pi_i^B\\)\nProbability of belonging to a probability sample for the given unit\n\n\n\\(\\pi_i^A\\)\nProbability of belonging to a non-probability sample for the given unit\n\n\n\\(\\dot{\\pi}_i^A(\\cdot)\\)\nDerivative of \\(\\pi_i^A\\) at point \\(\\cdot\\)\n\n\n\\(d_i^B\\)\nDesign weight for the given unit in a probability sample\n\n\n\\(n_A\\)\nSize of non-probability sample\n\n\n\\(n_B\\)\nSize of probability sample\n\n\n\\(\\mu_{y}\\)\nMean of population for response variable\n\n\n\\(R_{i}^A\\)\nAn indicator function for nonprobability sample\n\n\n\\(\\omega_i\\)\nFrequency weight\n\n\n\\(\\ell\\)\nLog-likelihood function for the model\n\n\n\\(\\hat{N}\\)\nPoint estimate for true population size\n\n\n\\(var\\)\nVariance operator\n\n\n\\(Diag(\\cdot)\\)\nA diagonal matrix constructed from vector \\(\\cdot\\)\n\n\n\\(\\btheta\\)\nSet of the parameters to estimate for selection model\n\n\n\\(\\bbeta\\)\nSet of the parameters to estimate for outcome model\n\n\n\\(\\phi(\\cdot)\\)\nProbability density function of the normal distribution in point \\(\\cdot\\)\n\n\n\\(\\Phi(\\cdot)\\)\nCumulative distribution function of the normal distribution in point \\(\\cdot\\)\n\n\n\\(\\hat{\\mu}_{MI}\\)\nMass imputation estimator of population mean\n\n\n\\(\\hat{\\mu}_{IPW}\\)\nInverse probability weighted estimator of population mean\n\n\n\\(\\hat{\\mu}_{DR}\\)\nDoubly robust estimator of population mean"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "ipw.html#maximum-likelihood-estimation",
    "href": "ipw.html#maximum-likelihood-estimation",
    "title": "3  Inverse probability weighting",
    "section": "3.2 Maximum likelihood estimation",
    "text": "3.2 Maximum likelihood estimation\nSuppose that propensity score can be modelled parametrically as \\(\\mathbb{P}\\left(R_i=1 \\mid \\bx_i\\right) = \\pi(\\bx_{i}, \\btheta_{0})\\). The maximum likelihood estimator is computed as \\(\\hat{\\pi}_{i}^{A} = \\pi(\\bx_{i}, \\hat{\\btheta}_{0})\\), where \\(\\hat{\\btheta}_{0}\\) is the maximizer of the following log-likelihood function:\n\\[\n\\begin{align}\n    \\begin{split}\n\\ell(\\boldsymbol{\\theta}) & =\\sum_{i=1}^N\\left\\{R_i \\log \\pi_i^{\\mathrm{A}}+\\left(1-R_i\\right) \\log \\left(1-\\pi_i^{\\mathrm{A}}\\right)\\right\\} \\\\ & =\\sum_{i \\in \\mathcal{S}_{\\mathrm{A}}} \\log \\left\\{\\frac{\\pi\\left(\\boldsymbol{x}_i, \\boldsymbol{\\theta}\\right)}{1-\\pi\\left(\\boldsymbol{x}_i, \\boldsymbol{\\theta}\\right)}\\right\\}+\\sum_{i=1}^N \\log \\left\\{1-\\pi\\left(\\boldsymbol{x}_i, \\boldsymbol{\\theta}\\right)\\right\\}\n    \\end{split}\n\\end{align}\n\\]\nSince we do not observe \\(\\bx_i\\) for all units, Yilin Chen, Pengfei Li & Changbao Wu presented following log-likelihood function is subject to data integration basing on samples \\(S_A\\) and \\(S_B\\). They proposed logistic regression model with \\(\\pi(\\bx_{i}, \\btheta) = \\frac{\\exp(\\bx_{i}^{\\top}\\btheta)}{\\exp(\\bx_{i}^{\\top}\\btheta) + 1}\\) in order to estimate \\(\\btheta\\). We expanded this approach on probit regression and complementary log-log model. For the sake of accuracy, let us recall that the probit and cloglog models are based on the assumption that model takes the form \\(\\pi(\\bx_{i},\\btheta) = \\Phi(\\bx_{i}^{\\top}\\btheta)\\) and \\(\\pi(\\bx_{i}, \\btheta) = 1 - \\exp(-\\exp(\\bx_{i}^{\\top}\\btheta))\\) respectively.\n\\[\n\\begin{align}\n    \\ell^{*}(\\btheta) = \\sum_{i \\in S_{A}}\\log \\left\\{\\frac{\\pi(\\bx_{i}, \\btheta)}{1 - \\pi(\\bx_{i},\\btheta)}\\right\\} + \\sum_{i \\in S_{B}}d_{i}^{B}\\log\\{1 - \\pi({\\bx_{i},\\btheta})\\}\n\\end{align}\n\\] In the following subsections we present the full derivation of the MLE, depending on the assumed model for the propensity score.\n\n3.2.1 Logistic regression\nLog-likelihood function with logistic regression is given by \\[\n\\ell^{*}(\\btheta) = \\sum_{i \\in S_A}\\bx_{i}^{\\top}\\btheta - \\sum_{i \\in S_B}d_{i}^{B}\\log\\{1 + \\exp(\\bx_{i}^{\\top}\\btheta)\\}\n\\] with analytical gradient and hessian given by \\[\n\\frac{\\partial \\ell^*}{\\partial\\btheta} = \\sum_{i \\in S_{A}}\\bx_{i} - \\sum_{i \\in S_{B}}d_{i}^{B}\\pi(\\bx_{i}, \\btheta)\\bx_{i}\n\\] and \\[\n    \\frac{\\partial^{2} \\ell^{*}}{\\partial\\btheta^{T} \\partial\\btheta} =- \\sum_{i \\in S_B}d_i^B\\pi(\\bx_i,\\btheta)(1 - \\pi(\\bx_i,\\btheta))\\bx_i\\bx_i^{\\top} = \\bX_B^{\\top}\\operatorname{\\bW}_{B}\\bX_B,\n\\] respectively, where \\[\n\\begin{align*}\n    \\operatorname{\\bW}_{B} =\n    diag & \\left(-d_1^B\\pi(\\bx_{1},\\btheta)(1 - \\pi(\\bx_{1},\\btheta)), -d_2^B\\pi(\\bx_{2},\\btheta)(1 - \\pi(\\bx_{2},\\btheta)), \\right. \\\\\n     & \\left. \\ldots, -d_{n_{B}}^{B}\\pi(\\bx_{n_{B}},\\btheta)(1 - \\pi(x_{n_{B}},\\btheta))\\right).\n\\end{align*}\n\\]\n\n\n3.2.2 Complementary log-log regression\nSimilarly, log-likelihood function has form of \\[\n\\ell^{*}(\\btheta) = \\sum_{i \\in S_{A}}\\left\\{\\log\\{1 - \\exp(-\\exp(\\bx_{i}^{\\top}\\btheta))\\} + \\exp(\\bx_{i}^{\\top}\\btheta)\\right\\} - \\sum_{i \\in S_{B}} d_{i}^{B}\\exp(\\bx_{i}^{\\top}\\btheta)\n\\] with analytical gradient and hessian equal to \\[\n    \\frac{\\partial \\ell^*}{\\partial\\btheta} = \\sum_{i \\in S_{A}}\\frac{\\exp(\\bx_{i}^{\\top}\\btheta)\\bx_{i}}{\\pi(\\bx_{i}, \\btheta)} - \\sum_{i \\in S_{B}}d_{i}^{B}\\exp(\\bx_{i}^{T}\\btheta)\\bx_{i}\n\\] and \\[\n\\begin{align*}\n    \\begin{split}\n    \\frac{\\partial^{2} \\ell^{*}}{\\partial\\btheta^{T} \\partial\\btheta} & = \\sum_{i \\in S_A} \\frac{\\exp(\\bx_{i}^{\\top}\\btheta)}{\\pi(\\bx_{i}, \\btheta)} \\left\\{1 - \\frac{\\exp(\\bx_{i}^{\\top}\\btheta)}{\\pi(\\bx_{i}, \\btheta)} + \\exp(\\bx_{i}^{\\top}\\btheta)\\right\\}\\bx_i\\bx_i^{\\top} - \\sum_{i \\in S_B}d_i^B\\exp (\\bx_{i}^{\\top}\\btheta)\\bx_i\\bx_i^{\\top} \\\\ & = \\bX_A^{\\top}\\operatorname{\\bW}_{Ac}\\bX_A - \\bX_B^{\\top}\\operatorname{\\bW}_{Bc}\\bX_B,\n    \\end{split}\n\\end{align*}\n\\] respectively, where \\[\n\\begin{align*}\n    \\operatorname{\\bW}_{Ac} =  diag & \\left(\\frac{\\exp(\\bx_{1}^{\\top}\\btheta)}{\\pi(\\bx_{1}, \\btheta)} \\left\\{1 - \\frac{\\exp(\\bx_{1}^{\\top}\\btheta)}{\\pi(\\bx_{1}, \\btheta)} + \\exp(\\bx_{1}^{\\top}\\btheta)\\right\\}, \\right.\n    \\\\\n    & \\left. \\frac{\\exp(\\bx_{2}^{\\top}\\btheta)}{\\pi(\\bx_{2}, \\btheta)} \\left\\{1 - \\frac{\\exp(\\bx_{2}^{\\top}\\btheta)}{\\pi(\\bx_{2}, \\btheta)} + \\exp(\\bx_{2}^{\\top}\\btheta)\\right\\}, \\right.\n    \\\\\n    & \\left. \\ldots, \\right.\n    \\\\\n    & \\left. \\frac{\\exp(\\bx_{n_A}^{\\top}\\btheta)} {\\pi(\\bx_{n_A}, \\btheta)} \\left\\{1 - \\frac{\\exp(\\bx_{n_A}^{\\top}\\btheta)}{\\pi(\\bx_{n_A}, \\btheta)} + \\exp(\\bx_{n_A}^{\\top}\\btheta)\\right\\} \\right)\n\\end{align*}\n\\] and \\[\n\\begin{align*}\n    \\operatorname{\\bW}_{Bc} = diag \\left(d_1^B\\exp (\\bx_{1}^{\\top}\\btheta), d_2^B\\exp (\\bx_{2}^{\\top}\\btheta), \\ldots, d_{n_B}^B\\exp (\\bx_{n_{B}}^{\\top}\\btheta)\\right).\n\\end{align*}\n\\]\n\n\n3.2.3 Probit regression\nFor probit model calculations are as follow \\[\n\\begin{align*}\n    \\ell^{*}(\\btheta) & = \\sum_{i \\in S_{A}}\\log\\left\\{\\frac{\\Phi(\\bx_{i}^{\\top}\\btheta)}{1 - \\Phi(\\bx_{i}^{\\top}\\btheta)}\\right\\} + \\sum_{i \\in S_{B}}d_{i}^{B}\\log\\{1 - \\Phi(\\bx_{i}^{\\top}\\btheta)\\}\n\\end{align*}\n\\] with analytical gradient and hessian as \\[\n\\begin{align*}\n        \\frac{\\partial \\ell^*}{\\partial\\btheta} = \\sum_{i \\in S_A}\\frac{\\phi(\\bx_i^{\\top}\\btheta)}{\\Phi(\\bx_i^{\\top}\\btheta)(1 - \\Phi(\\bx_i^{\\top}\\btheta))}\\bx_i - \\sum_{i \\in S_B}d_i^B\\frac{\\phi(\\bx_i^{\\top}\\btheta)}{1 - \\Phi(\\bx_i^{\\top}\\btheta)}\\bx_i\n\\end{align*}\n\\] and \\[\n\\begin{align*}\n    \\begin{split}\n        \\frac{\\partial^{2} \\ell^{*}}{\\partial\\btheta^{T} \\partial\\btheta} & = \\sum_{i \\in S_A}\\Bigl\\{\\frac{\\bx_i^{\\top}\\btheta \\phi(\\bx_i^{\\top}\\btheta)}{\\Phi(\\bx_i^{\\top}\\btheta)(1 - \\Phi(\\bx_i^{\\top}\\btheta))} - \\frac{\\phi(\\bx_i^{\\top}\\btheta)^2}{\\Phi(\\bx_i^{\\top}\\btheta)^2(1 - \\Phi(\\bx_i^{\\top}\\btheta))^2} + \\frac{2\\cdot\\phi(\\bx_i^{\\top}\\btheta)^2}{\\Phi(\\bx_i^{\\top}\\btheta)(1 - \\Phi(\\bx_i^{\\top}\\btheta))^2}\\Bigr\\}\\bx_i\\bx_i^{\\top} \\\\ & - \\sum_{i \\in S_B}d_i^B\\Bigl\\{\\frac{\\bx_i^{\\top}\\btheta \\phi(\\bx_i^{\\top}\\btheta)}{1 - \\Phi(\\bx_i^{\\top}\\btheta)} + \\frac{\\phi(\\bx_i^{\\top}\\btheta)^2}{(1 - \\Phi(\\bx_i^{\\top}\\btheta))^2}\\Bigr\\}\\bx_i\\bx_i^{\\top} =     \\bX_A^{\\top}\\operatorname{\\bW}_{Ap}\\bX_A - \\bX_B^{\\top}\\operatorname{\\bW}_{Bp}\\bX_B,\n    \\end{split}\n\\end{align*}\n\\] where \\[\n\\begin{align*}\n    \\operatorname{\\bW}_{Ap} =  diag & \\left(\\Bigl\\{\\frac{\\bx_{1}^{\\top}\\btheta \\phi(\\bx_1^{\\top}\\btheta)}{\\Phi(\\bx_{1}^{\\top}\\btheta)(1 - \\Phi(\\bx_{1}^{\\top}\\btheta))} - \\frac{\\phi(\\bx_{1}^{\\top}\\btheta)^2}{\\Phi(\\bx_{1}^{\\top}\\btheta)^2(1 - \\Phi(\\bx_{1}^{\\top}\\btheta))^2} + \\frac{2\\cdot\\phi(\\bx_{1}^{\\top}\\btheta)^2}{\\Phi(\\bx_{1}^{\\top}\\btheta)(1 - \\Phi(\\bx_{1}^{\\top}\\btheta))^2}\\Bigr\\}\n    , \\right.\n    \\\\\n    & \\left. \\Bigl\\{\\frac{\\bx_{2}^{\\top}\\btheta \\phi(\\bx_{2}^{\\top}\\btheta)}{\\Phi(\\pmb{x}_{2}^{\\top}\\btheta)(1 - \\Phi(\\bx_{2}^{\\top}\\btheta))} - \\frac{\\phi(\\bx_{2}^{\\top}\\btheta)^2}{\\Phi(\\bx_{2}^{\\top}\\btheta)^2(1 - \\Phi(\\bx_{2}^{\\top}\\btheta))^2} + \\frac{2\\cdot\\phi(\\bx_{2}^{\\top}\\btheta)^2}{\\Phi(\\bx_{2}^{\\top}\\btheta)(1 - \\Phi(\\bx_{2}^{\\top}\\btheta))^2}\\Bigr\\},\n    \\right.\n    \\\\\n    & \\left. \\ldots, \\right.\n    \\\\\n    & \\left. \\Bigl\\{\\frac{\\bx_{n_{A}}^{\\top}\\btheta \\phi(\\bx_{n_{A}}^{\\top}\\btheta)}{\\Phi(\\bx_{n_{A}}^{\\top}\\btheta)(1 - \\Phi(\\bx_{n_{A}}^{\\top}\\btheta))} - \\frac{\\phi(\\bx_{n_{A}}^{\\top}\\btheta)^2}{\\Phi(\\bx_{n_{A}}^{\\top}\\btheta)^2(1 - \\Phi(\\bx_{n_{A}}^{\\top}\\btheta))^2} + \\frac{2\\cdot\\phi(\\bx_{n_{A}}^{\\top}\\btheta)^2}{\\Phi(\\bx_{n_{A}}^{\\top}\\btheta)(1 - \\Phi(\\bx_{n_{A}}^{\\top}\\btheta))^2}\\Bigr\\}\n    \\right)\n\\end{align*}\n\\] and \\[\n\\begin{align*}\n    \\operatorname{\\bW}_{Bp} = diag & \\left(d_1^B\\Bigl\\{\\frac{\\bx_{1}^{\\top}\\btheta \\phi(\\bx_{1}^{\\top}\\btheta)}{1 - \\Phi(\\bx_{1}^{\\top}\\btheta)} - \\frac{\\phi(\\bx_{1}^{\\top}\\btheta)^2}{(1 - \\Phi(\\bx_{1}^{\\top}\\btheta))^2}\\Bigr\\}, \\right.\n    \\\\\n    &\n    \\left. d_2^B\\Bigl\\{\\frac{\\bx_{2}^{\\top}\\btheta \\phi(\\bx_{2}^{\\top}\\btheta)}{1 - \\Phi(\\bx_{2}^{\\top}\\btheta)} - \\frac{\\phi(\\bx_{2}^{\\top}\\btheta)^2}{(1 - \\Phi(\\bx_{2}^{\\top}\\btheta))^2}\\Bigr\\}, \\right.\n    \\\\\n    & \\left. \\ldots, \\right.\n    \\\\\n    & \\left. d_{n_{B}}^B\\Bigl\\{\\frac{\\bx_{n_{B}}^{\\top}\\btheta \\phi(\\bx_{n_{B}}^{\\top}\\btheta)}{1 - \\Phi(\\bx_{n_{B}}^{\\top}\\btheta)} - \\frac{\\phi(\\bx_{n_{B}}^{\\top}\\btheta)^2}{(1 - \\Phi(\\bx_{n_{B}}^{\\top}\\btheta))^2}\\Bigr\\}\\right).\n\\end{align*}\n\\] respectively. \\(\\hat{\\btheta}\\) can be found by using the following Netwon-Raphson’s iterative method: \\[\n\\btheta^{(m)} = \\btheta^{(m-1)} - \\{H(\\btheta^{(m-1)}\\}^{-1}U(\\btheta^{(m-1})),\n\\] where \\(\\operatorname{H}\\) - hessian, \\(\\operatorname{U}\\) - gradient."
  },
  {
    "objectID": "ipw.html#general-estimating-equations",
    "href": "ipw.html#general-estimating-equations",
    "title": "3  Inverse probability weighting",
    "section": "3.3 General estimating equations",
    "text": "3.3 General estimating equations\nThe pseudo score equations derived from Maximum Likelihood Estimation methods may be replaced by a system of general estimating equations. Let \\(\\operatorname{h}\\left(\\bx\\right)\\) be the smooth function and \\[\n\\begin{equation}\n\\mathbf{U}(\\btheta)=\\sum_{i \\in S_A} \\mathbf{h}\\left(\\mathbf{x}_i, \\btheta\\right)-\\sum_{i \\in S_B} d_i^B \\pi\\left(\\mathbf{x}_i, \\btheta\\right) \\mathbf{h}\\left(\\mathbf{x}_i, \\btheta\\right).\n\\end{equation}\n\\] Under \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i\\) and logistic model for propensity score, Equation (2.1) looks like disorted version of the score equation from MLE method. Then \\[\n\\begin{align*}\n    \\mathbf{U}(\\btheta)=\\sum_{i \\in S_A} \\bx_i -\\sum_{i \\in S_B} d_i^B \\pi\\left(\\mathbf{x}_i, \\btheta\\right) \\bx_i.\n\\end{align*}\n\\] and analytical Jacobian is given by \\[\n\\begin{align*}\n\\frac{\\partial \\mathbf{U}}{\\partial\\btheta} = - \\sum_{i \\in S_B} d_i^B \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right) \\left(1 -  \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)\\right)\\bx_i \\bx_i^{\\mathrm{T}}.\n\\end{align*}\n\\] The second proposed of the smooth function in the literature is \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^{-1}\\), for which the \\(\\operatorname{U}\\)-function takes the following form \\[\n\\begin{align}\n    \\mathbf{U}(\\btheta)=\\sum_{i \\in S_A}  \\bx_i \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^{-1} -\\sum_{i \\in S_B} d_i^B \\bx_i.\n\\end{align}\n\\] Generally, the goal is to find solution for following system of equations \\[\n\\begin{equation*}\n    \\sum_{i \\in S_A} \\mathbf{h}\\left(\\mathbf{x}_i, \\btheta\\right) = \\sum_{i \\in S_B} d_i^B \\pi\\left(\\mathbf{x}_i, \\btheta\\right) \\mathbf{h}\\left(\\mathbf{x}_i, \\btheta\\right)\n\\end{equation*}\n\\] In total, we have six models for this estimation method depending on the \\(\\operatorname{h}\\)-function and the way propensity score is parameterized. Let us present all of them.\n\n3.3.1 Logistic regression\nAs the one model for logistic regression is presented above, we have equation under \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^{-1}\\) to consider. Analytical jacobian is given by \\[\n\\begin{align*}\n    \\frac{\\partial \\operatorname{U}(\\btheta)}{\\partial \\btheta} = -\\sum_{i \\in S_A} \\frac{1 - \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)} \\bx_i \\bx_i^{\\mathrm{T}}.\n\\end{align*}\n\\]\n\n\n3.3.2 Complementary log-log regression\nFor \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^{-1}\\) analytical jacobian is given by \\[\n\\begin{align*}\n    \\frac{\\partial \\operatorname{U}(\\btheta)}{\\partial \\btheta} = - \\sum_{i \\in S_A} \\frac{1 - \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^2} \\exp(\\bx_i^{\\mathrm{T}} \\btheta) \\bx_i \\bx_i^{\\mathrm{T}}\n\\end{align*}\n\\] and \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i\\) we have \\[\n\\begin{align*}\n    \\frac{\\partial \\operatorname{U}(\\btheta)}{\\partial \\btheta} = - \\sum_{i \\in S_B} \\frac{1 - \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^B} \\exp \\left(\\bx_i^\\mathrm{T} \\btheta\\right) \\bx_i \\bx_i^{\\mathrm{T}}.\n\\end{align*}\n\\]\n\n\n3.3.3 Probit regression\nSimilarly, for the probit model, under \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^{-1}\\) analyical jacobian is given by \\[\n\\begin{align*}\n    \\frac{\\partial \\operatorname{U}(\\btheta)}{\\partial \\btheta} = - \\sum_{i \\in S_A} \\frac{\\dot{\\pi}_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^2} \\bx_i \\bx_i^{\\mathrm{T}}\n\\end{align*}\n\\] and under \\(\\operatorname{h}\\left(\\bx_i\\right) = \\bx_i\\) we have\n\\[\n\\begin{align*}\n    \\frac{\\partial \\operatorname{U}(\\partial \\btheta)}{\\btheta} = - \\sum_{i \\in S_B} \\frac{\\dot{\\pi}_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^B} \\bx_i \\bx_i^{\\mathrm{T}}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "mi.html#nearest-neighbor",
    "href": "mi.html#nearest-neighbor",
    "title": "4  Mass imputation",
    "section": "4.2 Nearest neighbor",
    "text": "4.2 Nearest neighbor"
  },
  {
    "objectID": "variableselection.html#scad",
    "href": "variableselection.html#scad",
    "title": "6  Techniques of variables selection for high-dimensional data",
    "section": "6.2 SCAD",
    "text": "6.2 SCAD\n\\[\np_{\\lambda}(x ; \\gamma)= \\begin{cases}\\lambda|x| & \\text { if }|x| \\leq \\lambda, \\\\ \\frac{2 \\gamma \\lambda|x|-x^2-\\lambda^2}{2(\\gamma-1)} & \\text { if } \\lambda<|x|<\\gamma \\lambda \\\\ \\frac{\\lambda^2(\\gamma+1)}{2} & \\text { if }|x| \\geq \\gamma \\lambda\\end{cases}\n\\] and derivative is \\[\nq_{\\lambda}(x ;  \\gamma)= \\begin{cases}\\lambda & \\text { if }|x| \\leq \\lambda \\\\ \\frac{\\gamma \\lambda-|x|}{\\gamma-1} & \\text { if } \\lambda<|x|<\\gamma \\lambda \\\\ 0 & \\text { if }|x| \\geq \\gamma \\lambda\\end{cases}\n\\]"
  },
  {
    "objectID": "variableselection.html#mcp",
    "href": "variableselection.html#mcp",
    "title": "6  Techniques of variables selection for high-dimensional data",
    "section": "6.3 MCP",
    "text": "6.3 MCP\n\\[\np_{\\lambda}(x ; \\gamma)= \\begin{cases}\\lambda|x|-\\frac{x^2}{2 \\gamma}, & \\text { if }|x| \\leq \\gamma \\lambda \\\\ \\frac{1}{2} \\gamma \\lambda^2, & \\text { if }|x|>\\gamma \\lambda\\end{cases}\n\\] and derivative is \\[\nq_\\lambda(x ; \\gamma)= \\begin{cases}\\left(\\lambda-\\frac{|x|}{\\gamma}\\right) \\operatorname{sign}(x), & \\text { if }|x| \\leq \\gamma \\lambda, \\\\ 0, & \\text { if }|x|>\\gamma \\lambda\\end{cases}\n\\]"
  },
  {
    "objectID": "variableselection.html#lasso",
    "href": "variableselection.html#lasso",
    "title": "6  Techniques of variables selection for high-dimensional data",
    "section": "6.1 LASSO",
    "text": "6.1 LASSO\n\\[\np_{\\lambda}(x) = \\lambda |x|\n\\] and its derivative\n\\[\np_{\\lambda}(x)= \\begin{cases} - \\lambda & \\text { if }x < 0, \\\\ \\left[-\\lambda, \\lambda\\right] & \\text { if } x = 0 \\\\ \\lambda & \\text { if }x > 0\\end{cases}\n\\]"
  },
  {
    "objectID": "dr.html",
    "href": "dr.html",
    "title": "5  Doubly robust methods",
    "section": "",
    "text": "\\[\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bOmega}{\\boldsymbol{\\Omega}}\n\\newcommand{\\bTheta}{\\boldsymbol{\\Theta}}\n\\newcommand{\\bPi}{\\boldsymbol{\\Pi}}\n\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n\\newcommand{\\brho}{\\boldsymbol{\\rho}}\n\\newcommand{\\beps}{\\boldsymbol{\\epsilon}}\n\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n\\newcommand{\\bgamma}{\\boldsymbol{\\gamma}}\n\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bpi}{\\boldsymbol{\\pi}}\n\\newcommand{\\bphi}{\\boldsymbol{\\phi}}\n\\newcommand{\\bPhi}{\\boldsymbol{\\Phi}}\n\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n\\newcommand{\\bx}{\\boldsymbol{x}}\n\\newcommand{\\bD}{\\boldsymbol{D}}\n\\newcommand{\\bV}{\\boldsymbol{V}}\n\\newcommand{\\bv}{\\boldsymbol{v}}\n\\newcommand{\\bY}{\\boldsymbol{Y}}\n\\newcommand{\\bA}{\\boldsymbol{A}}\n\\newcommand{\\bB}{\\boldsymbol{B}}\n\\newcommand{\\bR}{\\boldsymbol{R}}\n\\newcommand{\\bM}{\\boldsymbol{M}}\n\\newcommand{\\bI}{\\boldsymbol{I}}\n\\newcommand{\\bC}{\\boldsymbol{C}}\n\\newcommand{\\bW}{\\boldsymbol{W}}\n\\newcommand{\\bw}{\\boldsymbol{w}}\n\\newcommand{\\bd}{\\boldsymbol{d}}\n\\newcommand{\\bT}{\\boldsymbol{T}}\n\\newcommand{\\bt}{\\boldsymbol{t}}\n\\newcommand{\\bZ}{\\boldsymbol{Z}}\n\\newcommand{\\bX}{\\boldsymbol{X}}\n\\newcommand{\\bz}{\\boldsymbol{z}}\n\\newcommand{\\by}{\\boldsymbol{y}}\n\\newcommand{\\br}{\\boldsymbol{r}}\n\\newcommand{\\bp}{\\boldsymbol{p}}\n\\newcommand{\\bb}{\\boldsymbol{b}}\n\\newcommand{\\bZero}{\\boldsymbol{0}}\n\\newcommand{\\bOne}{\\boldsymbol{1}}\n\\]"
  },
  {
    "objectID": "dr.html#bias-minimization-technique",
    "href": "dr.html#bias-minimization-technique",
    "title": "5  Doubly robust methods",
    "section": "5.1 Bias minimization technique",
    "text": "5.1 Bias minimization technique\nThis model is derived from the form of the bias of doubly robust estimator. We consider set of estimating equations, for which we want to find regression parameters (\\(\\btheta, \\bbeta\\)). Shu Yang, Jae Kwang Kim and Rui Song proposed this method with logistic regression for selection model. As before our goal is to expand this approach. At the beginning let us derive bias of the estimator. We have\n\\[\n\\begin{aligned}\nbias(\\hat{\\mu}_{DR}) = & \\mathbb{E}\\left\\{\\hat{\\mu}_{DR} - \\mu\\right\\} \\\\ = & \\mathbb{E}\\left[ \\frac{1}{N} \\sum_{i=1}^N \\left\\{\\frac{R_i^A}{\\pi_i^A \\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}  - 1\\right\\} \\left\\{y_i - \\operatorname{m}\\left( \\bx_i^{\\mathrm{T}} \\bbeta\\right)\\right\\} \\right] \\\\ + & \\mathbb{E}\\left[  \\frac{1}{N} \\sum_{i=1}^N \\left(R_i^B d_i^B - 1\\right) \\operatorname{m}\\left( \\bx_i^{\\mathrm{T}} \\bbeta \\right)\\right]\n\\end{aligned}\n\\] Since we actually care about minimizing the square of the load, let’s calculate its derivative against the parameter vector. \\[\n\\begin{aligned}\n    \\frac{\\partial \\operatorname{bias}(\\hat{\\mu}_{DR})^2}{\\partial \\left(\\bbeta^{\\mathrm{T}}, \\btheta^{\\mathrm{T}}\\right)^{\\mathrm{T}}} = 2 \\operatorname{bias}(\\hat{\\mu}_{DR}) J(\\theta, \\beta),\n\\end{aligned}\n\\] where \\(J(\\theta, \\beta)\\) is internal derivative and depends on the model for outcome variable and propensity score. In the basic setting with propensity score modelling by logistic regression we have following system of equations to solve \\[\n\\begin{equation}\n\\begin{aligned}\nJ(\\theta, \\beta)=\\left(\\begin{array}{c}\nJ_1(\\theta, \\beta) \\\\\nJ_2(\\theta, \\beta)\n\\end{array}\\right)=\\left(\\begin{array}{c}\n\\sum_{i=1}^N R_i^A\\left\\{\\frac{1}{\\pi\\left(\\boldsymbol{x}_i, \\boldsymbol{\\theta}\\right)}-1\\right\\}\\left\\{y_i-m\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right)\\right\\} \\boldsymbol{x}_i \\\\\n\\sum_{i=1}^N \\frac{R_i^A}{\\pi\\left(\\boldsymbol{x}_i, \\boldsymbol{\\theta}\\right)} \\frac{\\partial m\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right)}{\\partial \\bbeta}  - \\sum_{i \\in \\mathcal{S}_{\\mathrm{B}}} d_i^{\\mathrm{B}} \\frac{\\partial m\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right)}{\\partial \\bbeta}\n\\end{array}\\right)\n\\end{aligned}\n\\end{equation}\n\\] where \\(\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right)\\) is working model for outcome variable, for example in linear regression case we have \\[\nm\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right) = \\bx_i^{T} \\bbeta\n\\] and \\[\n\\frac{\\partial m\\left(\\boldsymbol{x}_i, \\boldsymbol{\\beta}\\right)}{\\partial \\bbeta} = \\bx_i.\n\\] For complementary log-log model we have \\[\n\\begin{equation}\nJ(\\theta, \\beta)=\\left(\\begin{array}{c}\nJ_1(\\theta, \\beta) \\\\\nJ_2(\\theta, \\beta)\n\\end{array}\\right)=\\left(\\begin{array}{c}\n\\frac{1}{N} \\sum_{i=1}^N R_i^A\\left\\{\\frac{1 - \\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^2} \\exp(\\bx_i^{\\mathrm{T}} \\btheta)\\right\\}\\left\\{y_i-m\\left(\\bx_i^{\\mathrm{T}} \\beta\\right)\\right\\} \\bx_i \\\\\n\\frac{1}{N} \\sum_{i=1}^N\\left\\{\\frac{R_i^A}{\\pi_i^A\\left(\\bx^{\\mathrm{T}}\\theta\\right)}-d_i^B R_i^B\\right\\} \\frac{\\partial m\\left(\\bx_i^{\\mathrm{T}} \\beta\\right)}{\\partial \\beta}\n\\end{array}\\right)\n\\end{equation}\n\\] and probit model\n\\[\n\\begin{equation}\nJ(\\theta, \\beta)=\\left(\\begin{array}{c}\nJ_1(\\theta, \\beta) \\\\\nJ_2(\\theta, \\beta)\n\\end{array}\\right)=\\left(\\begin{array}{c}\n\\frac{1}{N} \\sum_{i=1}^N R_i^A\\frac{\\dot{\\pi_i^A}\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)}{\\pi_i^A\\left(\\bx_i^{\\mathrm{T}} \\btheta \\right)^2} \\left\\{y_i-m\\left(\\bx_i^{\\mathrm{T}} \\beta\\right)\\right\\} \\bx_i \\\\\n\\frac{1}{N} \\sum_{i=1}^N\\left\\{\\frac{R_i^A}{\\pi_i^A\\left(\\bx^{\\mathrm{T}}\\theta\\right)}-d_i^B R_i^B\\right\\} \\frac{\\partial m\\left(\\bx_i^{\\mathrm{T}} \\beta\\right)}{\\partial \\beta}\n\\end{array}\\right)\n\\end{equation}\n\\]\nGoal is to solve following system of equations \\[\nJ(\\theta, \\beta)=\\bZero\n\\]"
  },
  {
    "objectID": "ipw.html#motivation-and-assumptions",
    "href": "ipw.html#motivation-and-assumptions",
    "title": "3  Inverse probability weighting",
    "section": "3.1 Motivation and assumptions",
    "text": "3.1 Motivation and assumptions\nLet \\(\\mathcal{U}=\\{1,2, \\ldots, N\\}\\) represent the finite population with N units and \\(\\left\\{\\left(\\bx_i, y_i\\right), i \\in \\mathcal{S}_{\\mathrm{A}}\\right\\}\\) and \\(\\{\\left(\\bx_i, d_i^B), i \\in \\mathcal{S}_{\\mathrm{B}}\\right\\}\\) be the datasets from non-probability and probability samples respectively. Following assumptions are required for this model:\n\nThe selection indicator \\(R_i\\) and the response variable \\(y_i\\) are independent given the set of covariates \\(x_i\\).\nAll units have a nonzero propensity score, that is, \\(\\pi_i^A > 0\\) for all \\(i\\).\nThe indicator variables \\(R_i^A\\) and \\(R_j^A\\) are independent for given \\(x_i\\) and \\(x_j\\) for \\(i \\neq j\\)."
  },
  {
    "objectID": "mi.html#model-based-methods",
    "href": "mi.html#model-based-methods",
    "title": "4  Mass imputation",
    "section": "4.2 Model-based methods",
    "text": "4.2 Model-based methods\nThis method is based on parametric model on sample \\(S_A\\) in the form of\n\\[\n\\begin{equation}\n\\mathbb{E}\\left(y_i \\mid \\bx_i\\right) = m\\left(\\bx_i, \\bbeta_{0}\\right)\n\\end{equation}\n\\]\nfor some unknown \\(\\bbeta_{0}\\) and known function \\(m(\\cdot)\\). The specification of m-function typically follows the mean function for generalized linear models. i \\(\\by\\) is continous, we can use linear regression model with \\(m\\left(\\boldsymbol{x}_i, \\bbeta_{0}\\right) = \\bx_i^{T} \\bbeta_0\\). If \\(\\by\\) one can use logistic regression model and let \\(m\\left(\\boldsymbol{x}_i, \\bbeta_{0}\\right) = \\frac{\\exp\\left( \\bx_i^{T} \\bbeta_0\\right)}{\\exp\\left( \\bx_i^{T} \\bbeta_0\\right) + 1}\\). If \\(\\by\\) represents count data, we can use log-linear model, where \\(m\\left(\\boldsymbol{x}_i, \\bbeta_{0}\\right) = \\exp\\left(\\bx_i^{T} \\bbeta_0\\right)\\)\nMass imputation estimator\n\\[\n\\begin{equation}\n\\frac{1}{\\hat{N}^{\\mathrm{B}}} \\sum_{i \\in \\mathcal{S}_{\\mathrm{B}}} d_i^{\\mathrm{B}} m\\left(\\boldsymbol{x}_i, \\hat{\\bbeta}\\right)\n\\end{equation}\n\\] Variance of an estimator"
  },
  {
    "objectID": "ipw.html",
    "href": "ipw.html",
    "title": "3  Inverse probability weighting",
    "section": "",
    "text": "\\[\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bOmega}{\\boldsymbol{\\Omega}}\n\\newcommand{\\bTheta}{\\boldsymbol{\\Theta}}\n\\newcommand{\\bPi}{\\boldsymbol{\\Pi}}\n\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n\\newcommand{\\brho}{\\boldsymbol{\\rho}}\n\\newcommand{\\beps}{\\boldsymbol{\\epsilon}}\n\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n\\newcommand{\\bgamma}{\\boldsymbol{\\gamma}}\n\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bpi}{\\boldsymbol{\\pi}}\n\\newcommand{\\bphi}{\\boldsymbol{\\phi}}\n\\newcommand{\\bPhi}{\\boldsymbol{\\Phi}}\n\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n\\newcommand{\\bx}{\\boldsymbol{x}}\n\\newcommand{\\bD}{\\boldsymbol{D}}\n\\newcommand{\\bV}{\\boldsymbol{V}}\n\\newcommand{\\bv}{\\boldsymbol{v}}\n\\newcommand{\\bY}{\\boldsymbol{Y}}\n\\newcommand{\\bA}{\\boldsymbol{A}}\n\\newcommand{\\bB}{\\boldsymbol{B}}\n\\newcommand{\\bR}{\\boldsymbol{R}}\n\\newcommand{\\bM}{\\boldsymbol{M}}\n\\newcommand{\\bI}{\\boldsymbol{I}}\n\\newcommand{\\bC}{\\boldsymbol{C}}\n\\newcommand{\\bW}{\\boldsymbol{W}}\n\\newcommand{\\bw}{\\boldsymbol{w}}\n\\newcommand{\\bd}{\\boldsymbol{d}}\n\\newcommand{\\bT}{\\boldsymbol{T}}\n\\newcommand{\\bt}{\\boldsymbol{t}}\n\\newcommand{\\bZ}{\\boldsymbol{Z}}\n\\newcommand{\\bX}{\\boldsymbol{X}}\n\\newcommand{\\bz}{\\boldsymbol{z}}\n\\newcommand{\\by}{\\boldsymbol{y}}\n\\newcommand{\\br}{\\boldsymbol{r}}\n\\newcommand{\\bp}{\\boldsymbol{p}}\n\\newcommand{\\bb}{\\boldsymbol{b}}\n\\newcommand{\\bZero}{\\boldsymbol{0}}\n\\newcommand{\\bOne}{\\boldsymbol{1}}\n\\]"
  },
  {
    "objectID": "mi.html",
    "href": "mi.html",
    "title": "4  Mass imputation",
    "section": "",
    "text": "\\[\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bOmega}{\\boldsymbol{\\Omega}}\n\\newcommand{\\bTheta}{\\boldsymbol{\\Theta}}\n\\newcommand{\\bPi}{\\boldsymbol{\\Pi}}\n\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n\\newcommand{\\brho}{\\boldsymbol{\\rho}}\n\\newcommand{\\beps}{\\boldsymbol{\\epsilon}}\n\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n\\newcommand{\\bgamma}{\\boldsymbol{\\gamma}}\n\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bpi}{\\boldsymbol{\\pi}}\n\\newcommand{\\bphi}{\\boldsymbol{\\phi}}\n\\newcommand{\\bPhi}{\\boldsymbol{\\Phi}}\n\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n\\newcommand{\\bx}{\\boldsymbol{x}}\n\\newcommand{\\bD}{\\boldsymbol{D}}\n\\newcommand{\\bV}{\\boldsymbol{V}}\n\\newcommand{\\bv}{\\boldsymbol{v}}\n\\newcommand{\\bY}{\\boldsymbol{Y}}\n\\newcommand{\\bA}{\\boldsymbol{A}}\n\\newcommand{\\bB}{\\boldsymbol{B}}\n\\newcommand{\\bR}{\\boldsymbol{R}}\n\\newcommand{\\bM}{\\boldsymbol{M}}\n\\newcommand{\\bI}{\\boldsymbol{I}}\n\\newcommand{\\bC}{\\boldsymbol{C}}\n\\newcommand{\\bW}{\\boldsymbol{W}}\n\\newcommand{\\bw}{\\boldsymbol{w}}\n\\newcommand{\\bd}{\\boldsymbol{d}}\n\\newcommand{\\bT}{\\boldsymbol{T}}\n\\newcommand{\\bt}{\\boldsymbol{t}}\n\\newcommand{\\bZ}{\\boldsymbol{Z}}\n\\newcommand{\\bX}{\\boldsymbol{X}}\n\\newcommand{\\bz}{\\boldsymbol{z}}\n\\newcommand{\\by}{\\boldsymbol{y}}\n\\newcommand{\\br}{\\boldsymbol{r}}\n\\newcommand{\\bp}{\\boldsymbol{p}}\n\\newcommand{\\bb}{\\boldsymbol{b}}\n\\newcommand{\\bZero}{\\boldsymbol{0}}\n\\newcommand{\\bOne}{\\boldsymbol{1}}\n\\]"
  },
  {
    "objectID": "mi.html#motivation-and-assumptions",
    "href": "mi.html#motivation-and-assumptions",
    "title": "4  Mass imputation",
    "section": "4.1 Motivation and Assumptions",
    "text": "4.1 Motivation and Assumptions"
  },
  {
    "objectID": "mi.html#nearest-neighbor-imputation",
    "href": "mi.html#nearest-neighbor-imputation",
    "title": "4  Mass imputation",
    "section": "4.3 Nearest neighbor imputation",
    "text": "4.3 Nearest neighbor imputation\n\n4.3.1 Assumptions\n\n\n4.3.2 model\nOn the other hand we can applied to this problem non-parametric method, such as nearest neighbor algorithm, that is, find the closest matching unit from sample \\(S_B\\) based on the \\(\\bX\\) values and use the corresponding \\(\\bY\\) value from this unit as the imputed value. Procedure contains two steps\n\nfor each \\(i \\in S_B\\) find the nearest neighbor from sample \\(S_A\\).\nCalculate the nearest neighbor imputation estimator of \\(\\mu_y\\) \\[\n\\begin{equation}\n\\hat{\\mu}_\\mathrm{nn}=\\frac{1}{N} \\sum_{i \\in S_B} d_i^B y_{i(1)} .\n\\end{equation}\n\\] Variance of an estimator\n\n\n\n4.3.3 K-nearest neighbor imputation\nSteps\n\nFor each unit \\(i \\in S_B\\) find the k nearest neighbors from sample \\(S_A\\). Impute the \\(\\bY\\) value for unit \\(i\\) by \\(\\hat{\\mu}\\left(\\mathbf{X}_i\\right)=k^{-1} \\sum_{j=1}^k Y_{i(j)}\\).\nCalculate k-neares neighbor imputation estimator of \\(\\mu_y\\) \\[\n\\hat{\\mu}_{\\mathrm{knn}}=\\frac{1}{N} \\sum_{i \\in S_B} d_i^B \\hat{\\mu}\\left(\\mathbf{X}_i\\right) .\n\\] Variance of an estimator"
  },
  {
    "objectID": "ipw.html#population-mean-estimator-and-its-properties",
    "href": "ipw.html#population-mean-estimator-and-its-properties",
    "title": "3  Inverse probability weighting",
    "section": "3.4 Population mean estimator and its properties",
    "text": "3.4 Population mean estimator and its properties\n\\[\n\\begin{equation*}\n    \\hat{\\mu}_{IPW1} = \\frac{1}{N} \\sum_{i \\in S_A} \\frac{y_i}{\\hat{\\pi}_i^{A}}\n\\end{equation*}\n\\]\n\\[\n\\begin{equation*}\n    \\hat{\\mu}_{IPW2} = \\frac{1}{\\hat{N}^{A}} \\sum_{i \\in S_A} \\frac{y_i}{\\hat{\\pi}_i^{A}},\n\\end{equation*}\n\\] Variance of an estimator"
  },
  {
    "objectID": "dr.html#population-mean-estimator-and-its-variance",
    "href": "dr.html#population-mean-estimator-and-its-variance",
    "title": "5  Doubly robust methods",
    "section": "5.2 Population mean estimator and its variance",
    "text": "5.2 Population mean estimator and its variance\n\\[\n\\begin{equation*}\n    \\hat{\\mu}_{\\mathrm{DR}}=\\frac{1}{\\hat{N}^{\\mathrm{A}}} \\sum_{i \\in \\mathcal{S}_{\\mathrm{A}}} d_i^{\\mathrm{A}}\\left\\{y_i-m\\left(\\boldsymbol{x}_i, \\hat{\\boldsymbol{\\beta}}\\right)\\right\\}+\\frac{1}{\\hat{N}^{\\mathrm{B}}} \\sum_{i \\in \\mathcal{S}_{\\mathrm{B}}} d_i^{\\mathrm{B}} m\\left(\\boldsymbol{x}_i, \\hat{\\boldsymbol{\\beta}}\\right)\n\\end{equation*}\n\\] Variance of an estimator"
  },
  {
    "objectID": "variableselection.html",
    "href": "variableselection.html",
    "title": "6  Techniques of variables selection for high-dimensional data",
    "section": "",
    "text": "\\[\n\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n\\newcommand{\\bOmega}{\\boldsymbol{\\Omega}}\n\\newcommand{\\bTheta}{\\boldsymbol{\\Theta}}\n\\newcommand{\\bPi}{\\boldsymbol{\\Pi}}\n\\newcommand{\\bbeta}{\\boldsymbol{\\beta}}\n\\newcommand{\\balpha}{\\boldsymbol{\\alpha}}\n\\newcommand{\\brho}{\\boldsymbol{\\rho}}\n\\newcommand{\\beps}{\\boldsymbol{\\epsilon}}\n\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n\\newcommand{\\bgamma}{\\boldsymbol{\\gamma}}\n\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n\\newcommand{\\bpi}{\\boldsymbol{\\pi}}\n\\newcommand{\\bphi}{\\boldsymbol{\\phi}}\n\\newcommand{\\bPhi}{\\boldsymbol{\\Phi}}\n\\newcommand{\\boldeta}{\\boldsymbol{\\eta}}\n\\newcommand{\\bx}{\\boldsymbol{x}}\n\\newcommand{\\bD}{\\boldsymbol{D}}\n\\newcommand{\\bV}{\\boldsymbol{V}}\n\\newcommand{\\bv}{\\boldsymbol{v}}\n\\newcommand{\\bY}{\\boldsymbol{Y}}\n\\newcommand{\\bA}{\\boldsymbol{A}}\n\\newcommand{\\bB}{\\boldsymbol{B}}\n\\newcommand{\\bR}{\\boldsymbol{R}}\n\\newcommand{\\bM}{\\boldsymbol{M}}\n\\newcommand{\\bI}{\\boldsymbol{I}}\n\\newcommand{\\bC}{\\boldsymbol{C}}\n\\newcommand{\\bW}{\\boldsymbol{W}}\n\\newcommand{\\bw}{\\boldsymbol{w}}\n\\newcommand{\\bd}{\\boldsymbol{d}}\n\\newcommand{\\bT}{\\boldsymbol{T}}\n\\newcommand{\\bt}{\\boldsymbol{t}}\n\\newcommand{\\bZ}{\\boldsymbol{Z}}\n\\newcommand{\\bX}{\\boldsymbol{X}}\n\\newcommand{\\bz}{\\boldsymbol{z}}\n\\newcommand{\\by}{\\boldsymbol{y}}\n\\newcommand{\\br}{\\boldsymbol{r}}\n\\newcommand{\\bp}{\\boldsymbol{p}}\n\\newcommand{\\bb}{\\boldsymbol{b}}\n\\newcommand{\\bZero}{\\boldsymbol{0}}\n\\newcommand{\\bOne}{\\boldsymbol{1}}\n\\]\nLet \\(\\operatorname{U}\\left(\\btheta, \\bbeta\\right)\\) be the join estimating function for \\(\\left(\\btheta, \\bbeta\\right)\\). When p is large, we consider the penalized estimating functions for \\(\\left(\\btheta, \\bbeta\\right)\\) as\n\\[\n\\operatorname{U}^p\\left(\\btheta, \\bbeta\\right) = \\operatorname{U}\\left(\\btheta, \\bbeta\\right) -\\left(\\begin{array}{c}\nq_{\\lambda_\\theta}(|\\btheta|) \\operatorname{sgn}(\\btheta) \\\\\nq_{\\lambda_\\beta}(|\\bbeta|) \\operatorname{sgn}(\\bbeta)\n\\end{array}\\right),\n\\] where \\(q_{\\lambda_{\\theta}}\\) and \\(q_{\\lambda_{\\beta}}\\) are some smooth functions. We let \\(q_{\\lambda}\\left(x\\right) = \\frac{\\partial p_{\\lambda}}{\\partial x}\\), where \\(p_{\\lambda}\\) is some penalization function."
  },
  {
    "objectID": "variableselection.html#solution",
    "href": "variableselection.html#solution",
    "title": "6  Techniques of variables selection for high-dimensional data",
    "section": "6.4 Solution",
    "text": "6.4 Solution\nBy minorization-maximization algorithm, the penalized estimator \\(\\left(\\hat{\\btheta}, \\hat{\\bbeta}\\right)\\) satisfies\n\\[\n\\operatorname{U}^p\\left(\\hat{\\btheta}, \\hat{\\bbeta}\\right) = \\operatorname{U}\\left(\\hat{\\btheta}, \\hat{\\bbeta}\\right) -\\left(\\begin{array}{c}\nq_{\\lambda_\\hat{\\theta}}(|\\hat{\\btheta}|) \\operatorname{sgn}(\\hat{\\btheta}) \\frac{|\\hat{\\btheta}|}{\\epsilon + |\\hat{\\btheta}|} \\\\\nq_{\\lambda_\\hat{\\beta}}(|\\hat{\\bbeta}|) \\operatorname{sgn}(\\hat{\\bbeta}) \\frac{|\\hat{\\bbeta}|}{\\epsilon + |\\hat{\\bbeta}|}\n\\end{array}\\right) = \\bZero\n\\] Let \\(\\nabla\\left(\\btheta, \\bbeta \\right) = \\frac{\\partial \\operatorname{U}\\left(\\btheta, \\bbeta\\right)}{\\partial \\left(\\btheta^{T} \\bbeta^{T}\\right)^{T}} = Diag \\left(\\frac{\\partial U_1 \\left(\\btheta \\right)}{\\partial \\btheta^{T}}, \\frac{\\partial U_2 \\left(\\bbeta \\right)}{\\partial \\bbeta^{T}} \\right)\\), where \\(U_1\\) is objective function for selection model and \\(U_2\\) for outcome model. Let \\(\\boldsymbol{\\alpha} = \\left(\\btheta, \\bbeta\\right)\\) and\n\\[\n\\Lambda(\\boldsymbol{\\alpha})=\\left(\\begin{array}{ccc}\nq_{\\lambda_1}\\left(\\left|\\alpha_1\\right|\\right) & \\ldots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\ldots & q_{\\lambda_{2 p}}\\left(\\left|\\alpha_{2 p}\\right|\\right)\n\\end{array}\\right)\n\\] Newton-Raphson procedure for j-variable and k-update\n\\[\n\\hat{\\alpha}_j^{[k]}=\\hat{\\alpha}_j^{[k-1]}+\\left\\{\\nabla_{j j}\\left(\\hat{\\alpha}^{[k-1]}\\right)+N \\Lambda_{j j}\\left(\\hat{\\alpha}^{[k-1]}\\right)\\right\\}^{-1}\\left\\{U_j\\left(\\hat{\\alpha}^{[k-1]}\\right)-N \\Lambda_{j j}\\left(\\hat{\\alpha}^{[k-1]}\\right) \\hat{\\alpha}_j^{[k-1]}\\right\\}\n\\]\nIt is recommended to use K-fold cross validation for selectiing tuning parameters \\(\\left(\\lambda_{\\theta}, \\lambda_{\\beta}\\right)\\) which minimize following loss functions for set of parameters \\(\\balpha\\).\n\\[\n\\operatorname{Loss}\\left(\\lambda_\\theta\\right)=\\sum_{j=1}^p\\left(\\sum_{i=1}^N\\left[\\frac{R_i^A}{\\pi_i^A\\left\\{\\bx_i^{\\mathrm{T}} \\hat{\\theta}\\left(\\lambda_\\theta\\right)\\right\\}}-\\frac{I_{\\mathrm{A}, i}}{\\pi_{\\mathrm{A}, i}}\\right] \\bx_{i, j}\\right)^2,\n\\]\n\\[\n\\operatorname{Loss}\\left(\\lambda_\\beta\\right)=\\sum_{i=1}^N R_i^A\\left[y_i-m\\left\\{\\bx_i^{\\mathrm{T}} \\hat{\\beta}\\left(\\lambda_\\beta\\right)\\right\\}\\right]^2,\n\\] where \\(\\hat{\\theta}\\left(\\lambda_\\theta\\right)\\) and \\(\\hat{\\beta}\\left(\\lambda_\\beta\\right)\\) are penalized estimators with tuning parameters \\(\\lambda_\\theta\\), \\(\\lambda_\\beta\\) for selection and outcome model respectively."
  }
]